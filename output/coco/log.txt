2023-08-01 17:11:03,965 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 17:11:03,966 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 17:11:03,966 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 17:11:03,966 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 17:11:03,969 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 17:11:03,971 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 17:11:53,014 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 17:42:57,391 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 17:42:57,392 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 17:42:57,392 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 17:42:57,392 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 17:42:57,395 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 17:42:57,396 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 17:43:13,215 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 17:45:10,010 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 17:45:10,010 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 17:45:10,011 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 17:45:10,011 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 17:45:10,014 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 17:45:10,018 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 17:45:27,957 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 17:53:07,225 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 17:53:07,227 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 17:53:07,227 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 17:53:07,227 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 17:53:07,232 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 17:53:07,233 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 17:53:23,861 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 17:56:16,005 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 17:56:16,006 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 17:56:16,007 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 17:56:16,007 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 17:56:16,013 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 17:56:16,014 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 17:59:18,674 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 18:02:15,317 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 18:02:15,319 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 18:02:15,319 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 18:02:15,320 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 18:02:15,326 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 18:02:15,331 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 18:03:10,066 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 20:55:01,451 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 20:55:01,455 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 20:55:01,455 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 20:55:01,456 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 20:55:01,462 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 20:55:01,514 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 20:56:18,571 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 21:03:33,819 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 21:03:33,820 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 21:03:33,820 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 21:03:33,821 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 21:03:33,825 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 21:03:33,853 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 21:04:03,824 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 21:05:51,590 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 21:05:51,593 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 21:05:51,593 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 21:05:51,594 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 21:05:51,601 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 21:05:51,604 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 21:06:28,882 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 21:08:49,792 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 21:08:49,794 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 21:08:49,794 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 21:08:49,795 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 21:08:49,802 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 21:08:49,803 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 21:09:44,318 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 21:14:33,393 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 21:14:33,394 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 21:14:33,394 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 21:14:33,394 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 21:14:33,399 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 21:14:33,400 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 21:14:56,774 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-08-01 21:16:28,989 maskrcnn_benchmark INFO: Namespace(config_file='./configs/pretrain/glip_Swin_T_O365_GoldG.yaml', disable_output_distributed=False, distributed=False, local_rank=0, opts=['MODEL.WEIGHT', './MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth', 'DATASETS.TRAIN', "('coco_grounding_train', )", 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '-1', 'SOLVER.IMS_PER_BATCH', '3', 'SOLVER.USE_AMP', 'True', 'SOLVER.MAX_EPOCH', '2', 'TEST.DURING_TRAINING', 'False', 'TEST.IMS_PER_BATCH', '16', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.BASE_LR', '0.00001', 'SOLVER.LANG_LR', '0.00001', 'SOLVER.STEPS', '(0.67,0.89)', 'DATASETS.DISABLE_SHUFFLE', 'True', 'MODEL.DYHEAD.SCORE_AGG', 'MEAN', 'TEST.EVAL_TASK', 'detection', 'OUTPUT_DIR', './output/coco', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'linear_prob'], override_output_dir=None, save_original_config=False, skip_test=True, use_tensorboard=False)
2023-08-01 21:16:28,991 maskrcnn_benchmark INFO: Using 1 GPUs
2023-08-01 21:16:28,991 maskrcnn_benchmark INFO: Loaded configuration file ./configs/pretrain/glip_Swin_T_O365_GoldG.yaml
2023-08-01 21:16:28,992 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: True
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", "mixed_train_no_coco", "flickr30k_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-08-01 21:16:28,996 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('coco_grounding_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: True
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: True
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: ./MODEL/glip/glip_tiny_model_o365_goldg_cc_sbu.pth
OUTPUT_DIR: ./output/coco
PATHS_CATALOG: /ssd2/yangzesheng/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 1e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 3
  LANG_LR: 1e-05
  MAX_EPOCH: 2
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: linear_prob
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 16
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2023-08-01 21:16:28,997 maskrcnn_benchmark INFO: Saving config into: ./output/coco/config.yml
2023-08-01 21:16:57,495 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
